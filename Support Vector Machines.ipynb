{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c3fd1d019d7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "## Importing required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-f15c869862d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_reduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[1;34m''' Plot confusion matrix for given classifier and data. '''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "## Loading all functions\n",
    "def get_match_label(match):\n",
    "    ''' Derives a label for a given match. '''\n",
    "    \n",
    "    #Define variables\n",
    "    home_goals = match['home_team_goal']\n",
    "    away_goals = match['away_team_goal']\n",
    "     \n",
    "    label = pd.DataFrame()\n",
    "    label.loc[0,'match_api_id'] = match['match_api_id'] \n",
    "\n",
    "    #Identify match label  \n",
    "    if home_goals > away_goals:\n",
    "        label.loc[0,'label'] = \"Win\"\n",
    "    if home_goals == away_goals:\n",
    "        label.loc[0,'label'] = \"Draw\"\n",
    "    if home_goals < away_goals:\n",
    "        label.loc[0,'label'] = \"Defeat\"\n",
    "\n",
    "    #Return label        \n",
    "    return label.loc[0]\n",
    "    \n",
    "def get_fifa_stats(match, player_stats):\n",
    "    ''' Aggregates fifa stats for a given match. '''    \n",
    "    \n",
    "    #Define variables\n",
    "    match_id =  match.match_api_id\n",
    "    date = match['date']\n",
    "    players = ['home_player_1', 'home_player_2', 'home_player_3', \"home_player_4\", \"home_player_5\",\n",
    "               \"home_player_6\", \"home_player_7\", \"home_player_8\", \"home_player_9\", \"home_player_10\",\n",
    "               \"home_player_11\", \"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\",\n",
    "               \"away_player_5\", \"away_player_6\", \"away_player_7\", \"away_player_8\", \"away_player_9\",\n",
    "               \"away_player_10\", \"away_player_11\"]\n",
    "    player_stats_new = pd.DataFrame()\n",
    "    names = []\n",
    "    \n",
    "    #Loop through all players\n",
    "    for player in players:   \n",
    "            \n",
    "        #Get player ID\n",
    "        player_id = match[player]\n",
    "        \n",
    "        #Get player stats \n",
    "        stats = player_stats[player_stats.player_api_id == player_id]\n",
    "            \n",
    "        #Identify current stats       \n",
    "        current_stats = stats[stats.date < date].sort_values(by = 'date', ascending = False)[:1]\n",
    "        \n",
    "        if np.isnan(player_id) == True:\n",
    "            overall_rating = pd.Series(0)\n",
    "        else:\n",
    "            current_stats.reset_index(inplace = True, drop = True)\n",
    "            overall_rating = pd.Series(current_stats.loc[0, \"overall_rating\"])\n",
    "\n",
    "        #Rename stat\n",
    "        name = \"{}_overall_rating\".format(player)\n",
    "        names.append(name)\n",
    "            \n",
    "        #Aggregate stats\n",
    "        player_stats_new = pd.concat([player_stats_new, overall_rating], axis = 1)\n",
    "    \n",
    "    player_stats_new.columns = names        \n",
    "    player_stats_new['match_api_id'] = match_id\n",
    "\n",
    "    player_stats_new.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #Return player stats    \n",
    "    return player_stats_new.ix[0]\n",
    "\n",
    "def get_fifa_data(matches, player_stats, path = None, data_exists = False):\n",
    "    ''' Gets fifa data for all matches. '''  \n",
    "    \n",
    "    #Check if fifa data already exists\n",
    "    if data_exists == True:\n",
    "        \n",
    "        fifa_data = pd.read_pickle(path)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"Collecting fifa data for each match...\")       \n",
    "        start = time()\n",
    "        \n",
    "        #Apply get_fifa_stats for each match\n",
    "        fifa_data = matches.apply(lambda x :get_fifa_stats(x, player_stats), axis = 1)\n",
    "        \n",
    "        end = time()    \n",
    "        print(\"Fifa data collected in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    #Return fifa_data\n",
    "    return fifa_data\n",
    "\n",
    "def get_overall_fifa_rankings(fifa, get_overall = False):\n",
    "    ''' Get overall fifa rankings from fifa data. '''\n",
    "      \n",
    "    temp_data = fifa\n",
    "    \n",
    "    #Check if only overall player stats are desired\n",
    "    if get_overall == True:\n",
    "        \n",
    "        #Get overall stats\n",
    "        data = temp_data.loc[:,(fifa.columns.str.contains('overall_rating'))]\n",
    "        data.loc[:,'match_api_id'] = temp_data.loc[:,'match_api_id']\n",
    "    else:\n",
    "        \n",
    "        #Get all stats except for stat date\n",
    "        cols = fifa.loc[:,(fifa.columns.str.contains('date_stat'))]\n",
    "        temp_data = fifa.drop(cols.columns, axis = 1)        \n",
    "        data = temp_data\n",
    "    \n",
    "    #Return data\n",
    "    return data\n",
    "\n",
    "def get_last_matches(matches, date, team, x = 10):\n",
    "    ''' Get the last x matches of a given team. '''\n",
    "    \n",
    "    #Filter team matches from matches\n",
    "    team_matches = matches[(matches['home_team_api_id'] == team) | (matches['away_team_api_id'] == team)]\n",
    "                           \n",
    "    #Filter x last matches from team matches\n",
    "    last_matches = team_matches[team_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:x,:]\n",
    "    \n",
    "    #Return last matches\n",
    "    return last_matches\n",
    "    \n",
    "def get_last_matches_against_eachother(matches, date, home_team, away_team, x = 10):\n",
    "    ''' Get the last x matches of two given teams. '''\n",
    "    \n",
    "    #Find matches of both teams\n",
    "    home_matches = matches[(matches['home_team_api_id'] == home_team) & (matches['away_team_api_id'] == away_team)]    \n",
    "    away_matches = matches[(matches['home_team_api_id'] == away_team) & (matches['away_team_api_id'] == home_team)]  \n",
    "    total_matches = pd.concat([home_matches, away_matches])\n",
    "    \n",
    "    #Get last x matches\n",
    "    try:    \n",
    "        last_matches = total_matches[total_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:x,:]\n",
    "    except:\n",
    "        last_matches = total_matches[total_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:total_matches.shape[0],:]\n",
    "        \n",
    "        #Check for error in data\n",
    "        if(last_matches.shape[0] > x):\n",
    "            print(\"Error in obtaining matches\")\n",
    "            \n",
    "    #Return data\n",
    "    return last_matches\n",
    "\n",
    "def get_goals(matches, team):\n",
    "    ''' Get the goals of a specfic team from a set of matches. '''\n",
    "    \n",
    "    #Find home and away goals\n",
    "    home_goals = int(matches.home_team_goal[matches.home_team_api_id == team].sum())\n",
    "    away_goals = int(matches.away_team_goal[matches.away_team_api_id == team].sum())\n",
    "\n",
    "    total_goals = home_goals + away_goals\n",
    "    \n",
    "    #Return total goals\n",
    "    return total_goals\n",
    "\n",
    "def get_goals_conceided(matches, team):\n",
    "    ''' Get the goals conceided of a specfic team from a set of matches. '''\n",
    "\n",
    "    #Find home and away goals\n",
    "    home_goals = int(matches.home_team_goal[matches.away_team_api_id == team].sum())\n",
    "    away_goals = int(matches.away_team_goal[matches.home_team_api_id == team].sum())\n",
    "\n",
    "    total_goals = home_goals + away_goals\n",
    "\n",
    "    #Return total goals\n",
    "    return total_goals\n",
    "\n",
    "def get_wins(matches, team):\n",
    "    ''' Get the number of wins of a specfic team from a set of matches. '''\n",
    "    \n",
    "    #Find home and away wins\n",
    "    home_wins = int(matches.home_team_goal[(matches.home_team_api_id == team) & (matches.home_team_goal > matches.away_team_goal)].count())\n",
    "    away_wins = int(matches.away_team_goal[(matches.away_team_api_id == team) & (matches.away_team_goal > matches.home_team_goal)].count())\n",
    "\n",
    "    total_wins = home_wins + away_wins\n",
    "\n",
    "    #Return total wins\n",
    "    return total_wins      \n",
    "    \n",
    "def get_match_features(match, matches, x = 10):\n",
    "    ''' Create match specific features for a given match. '''\n",
    "    \n",
    "    #Define variables\n",
    "    date = match.date\n",
    "    home_team = match.home_team_api_id\n",
    "    away_team = match.away_team_api_id\n",
    "    \n",
    "    #Get last x matches of home and away team\n",
    "    matches_home_team = get_last_matches(matches, date, home_team, x = 10)\n",
    "    matches_away_team = get_last_matches(matches, date, away_team, x = 10)\n",
    "    \n",
    "    #Get last x matches of both teams against each other\n",
    "    last_matches_against = get_last_matches_against_eachother(matches, date, home_team, away_team, x = 3)\n",
    "    \n",
    "    #Create goal variables\n",
    "    home_goals = get_goals(matches_home_team, home_team)\n",
    "    away_goals = get_goals(matches_away_team, away_team)\n",
    "    home_goals_conceided = get_goals_conceided(matches_home_team, home_team)\n",
    "    away_goals_conceided = get_goals_conceided(matches_away_team, away_team)\n",
    "    \n",
    "    #Define result data frame\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    #Define ID features\n",
    "    result.loc[0, 'match_api_id'] = match.match_api_id\n",
    "    result.loc[0, 'league_id'] = match.league_id\n",
    "\n",
    "    #Create match features\n",
    "    result.loc[0, 'home_team_goals_difference'] = home_goals - home_goals_conceided\n",
    "    result.loc[0, 'away_team_goals_difference'] = away_goals - away_goals_conceided\n",
    "    result.loc[0, 'games_won_home_team'] = get_wins(matches_home_team, home_team) \n",
    "    result.loc[0, 'games_won_away_team'] = get_wins(matches_away_team, away_team)\n",
    "    result.loc[0, 'games_against_won'] = get_wins(last_matches_against, home_team)\n",
    "    result.loc[0, 'games_against_lost'] = get_wins(last_matches_against, away_team)\n",
    "    \n",
    "    #Return match features\n",
    "    return result.loc[0]\n",
    "\n",
    "def create_feables(matches, fifa, bookkeepers, get_overall = False, horizontal = True, x = 10, verbose = True):\n",
    "    ''' Create and aggregate features and labels for all matches. '''\n",
    "\n",
    "    #Get fifa stats features\n",
    "    fifa_stats = get_overall_fifa_rankings(fifa, get_overall)\n",
    "    \n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Generating match features...\")\n",
    "    start = time()\n",
    "    \n",
    "    #Get match features for all matches\n",
    "    match_stats = matches.apply(lambda x: get_match_features(x, matches, x = 10), axis = 1)\n",
    "    \n",
    "    #Create dummies for league ID feature\n",
    "    dummies = pd.get_dummies(match_stats['league_id']).rename(columns = lambda x: 'League_' + str(x))\n",
    "    match_stats = pd.concat([match_stats, dummies], axis = 1)\n",
    "    match_stats.drop(['league_id'], inplace = True, axis = 1)\n",
    "    \n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Match features generated in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    if verbose == True:    \n",
    "        print(\"Generating match labels...\")\n",
    "    start = time()\n",
    "    \n",
    "    #Create match labels\n",
    "    labels = matches.apply(get_match_label, axis = 1)\n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Match labels generated in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    if verbose == True:    \n",
    "        print(\"Generating bookkeeper data...\")\n",
    "    start = time()\n",
    "    \n",
    "    #Get bookkeeper quotas for all matches\n",
    "    bk_data = get_bookkeeper_data(matches, bookkeepers, horizontal = True)\n",
    "    bk_data.loc[:,'match_api_id'] = matches.loc[:,'match_api_id']\n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Bookkeeper data generated in {:.1f} minutes\".format((end - start)/60))\n",
    "\n",
    "    #Merges features and labels into one frame\n",
    "    features = pd.merge(match_stats, fifa_stats, on = 'match_api_id', how = 'left')\n",
    "    features = pd.merge(features, bk_data, on = 'match_api_id', how = 'left')\n",
    "    feables = pd.merge(features, labels, on = 'match_api_id', how = 'left')\n",
    "    \n",
    "    #Drop NA values\n",
    "    feables.dropna(inplace = True)\n",
    "    \n",
    "    #Return preprocessed data\n",
    "    return feables\n",
    "    \n",
    "def train_classifier(clf, dm_reduction, X_train, y_train, cv_sets, params, scorer, jobs, use_grid_search = True, \n",
    "                     best_components = None, best_params = None):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    #Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    \n",
    "    #Check if grid search should be applied\n",
    "    if use_grid_search == True: \n",
    "        \n",
    "        #Define pipeline of dm reduction and classifier\n",
    "        estimators = [('dm_reduce', dm_reduction), ('clf', clf)]\n",
    "        pipeline = Pipeline(estimators)\n",
    "        \n",
    "        #Grid search over pipeline and return best classifier\n",
    "        grid_obj = model_selection.GridSearchCV(pipeline, param_grid = params, scoring = scorer, cv = cv_sets, n_jobs = jobs)\n",
    "        grid_obj.fit(X_train, y_train)\n",
    "        best_pipe = grid_obj.best_estimator_\n",
    "    else:\n",
    "        \n",
    "        #Use best components that are known without grid search        \n",
    "        estimators = [('dm_reduce', dm_reduction(n_components = best_components)), ('clf', clf(best_params))]\n",
    "        pipeline = Pipeline(estimators)        \n",
    "        best_pipe = pipeline.fit(X_train, y_train)\n",
    "        \n",
    "    end = time()\n",
    "    \n",
    "    #Print the results\n",
    "    print(\"Trained {} in {:.1f} minutes\".format(clf.__class__.__name__, (end - start)/60))\n",
    "    \n",
    "    #Return best pipe\n",
    "    return best_pipe\n",
    "\n",
    "def predict_labels(clf, best_pipe, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on scorer. '''\n",
    "    \n",
    "    #Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(best_pipe.named_steps['dm_reduce'].transform(features))\n",
    "    end = time()\n",
    "    \n",
    "    #Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds\".format(end - start))\n",
    "    return accuracy_score(target.values, y_pred)\n",
    "    \n",
    "def train_calibrate_predict(clf, dm_reduction, X_train, y_train, X_calibrate, y_calibrate, X_test, y_test, cv_sets, params, scorer, jobs, \n",
    "                            use_grid_search = True, **kwargs):\n",
    "    ''' Train and predict using a classifer based on scorer. '''\n",
    "    \n",
    "    #Indicate the classifier and the training set size\n",
    "    print(\"Training a {} with {}...\".format(clf.__class__.__name__, dm_reduction.__class__.__name__))\n",
    "    \n",
    "    #Train the classifier\n",
    "    best_pipe = train_classifier(clf, dm_reduction, X_train, y_train, cv_sets, params, scorer, jobs)\n",
    "    \n",
    "    #Calibrate classifier\n",
    "    print(\"Calibrating probabilities of classifier...\")\n",
    "    start = time()    \n",
    "    clf = CalibratedClassifierCV(best_pipe.named_steps['clf'], cv= 'prefit', method='isotonic')\n",
    "    clf.fit(best_pipe.named_steps['dm_reduce'].transform(X_calibrate), y_calibrate)\n",
    "    end = time()\n",
    "    print(\"Calibrated {} in {:.1f} minutes\".format(clf.__class__.__name__, (end - start)/60))\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"Score of {} for training set: {:.4f}.\".format(clf.__class__.__name__, predict_labels(clf, best_pipe, X_train, y_train)))\n",
    "    print(\"Score of {} for test set: {:.4f}.\".format(clf.__class__.__name__, predict_labels(clf, best_pipe, X_test, y_test)))\n",
    "    \n",
    "    #Return classifier, dm reduction, and label predictions for train and test set\n",
    "    return clf, best_pipe.named_steps['dm_reduce'], predict_labels(clf, best_pipe, X_train, y_train), predict_labels(clf, best_pipe, X_test, y_test)\n",
    "        \n",
    "def convert_odds_to_prob(match_odds):\n",
    "    ''' Converts bookkeeper odds to probabilities. '''\n",
    "    \n",
    "    #Define variables\n",
    "    match_id = match_odds.loc[:,'match_api_id']\n",
    "    bookkeeper = match_odds.loc[:,'bookkeeper']    \n",
    "    win_odd = match_odds.loc[:,'Win']\n",
    "    draw_odd = match_odds.loc[:,'Draw']\n",
    "    loss_odd = match_odds.loc[:,'Defeat']\n",
    "    \n",
    "    #Converts odds to prob\n",
    "    win_prob = 1 / win_odd\n",
    "    draw_prob = 1 / draw_odd\n",
    "    loss_prob = 1 / loss_odd\n",
    "    \n",
    "    total_prob = win_prob + draw_prob + loss_prob\n",
    "    \n",
    "    probs = pd.DataFrame()\n",
    "    \n",
    "    #Define output format and scale probs by sum over all probs\n",
    "    probs.loc[:,'match_api_id'] = match_id\n",
    "    probs.loc[:,'bookkeeper'] = bookkeeper\n",
    "    probs.loc[:,'Win'] = win_prob / total_prob\n",
    "    probs.loc[:,'Draw'] = draw_prob / total_prob\n",
    "    probs.loc[:,'Defeat'] = loss_prob / total_prob\n",
    "    \n",
    "    #Return probs and meta data\n",
    "    return probs\n",
    "\n",
    "def get_bookkeeper_data(matches, bookkeepers, horizontal = True):\n",
    "    ''' Aggregates bookkeeper data for all matches and bookkeepers. '''\n",
    "    \n",
    "    bk_data = pd.DataFrame()\n",
    "    \n",
    "    #Loop through bookkeepers\n",
    "    for bookkeeper in bookkeepers:\n",
    "\n",
    "        #Find columns containing data of bookkeeper\n",
    "        temp_data = matches.loc[:,(matches.columns.str.contains(bookkeeper))]\n",
    "        temp_data.loc[:, 'bookkeeper'] = str(bookkeeper)\n",
    "        temp_data.loc[:, 'match_api_id'] = matches.loc[:, 'match_api_id']\n",
    "        \n",
    "        #Rename odds columns and convert to numeric\n",
    "        cols = temp_data.columns.values\n",
    "        cols[:3] = ['Win','Draw','Defeat']\n",
    "        temp_data.columns = cols\n",
    "        temp_data.loc[:,'Win'] = pd.to_numeric(temp_data['Win'])\n",
    "        temp_data.loc[:,'Draw'] = pd.to_numeric(temp_data['Draw'])\n",
    "        temp_data.loc[:,'Defeat'] = pd.to_numeric(temp_data['Defeat'])\n",
    "        \n",
    "        #Check if data should be aggregated horizontally\n",
    "        if(horizontal == True):\n",
    "            \n",
    "            #Convert data to probs\n",
    "            temp_data = convert_odds_to_prob(temp_data)\n",
    "            temp_data.drop('match_api_id', axis = 1, inplace = True)\n",
    "            temp_data.drop('bookkeeper', axis = 1, inplace = True)\n",
    "            \n",
    "            #Rename columns with bookkeeper names\n",
    "            win_name = bookkeeper + \"_\" + \"Win\"\n",
    "            draw_name = bookkeeper + \"_\" + \"Draw\"\n",
    "            defeat_name = bookkeeper + \"_\" + \"Defeat\"\n",
    "            temp_data.columns.values[:3] = [win_name, draw_name, defeat_name]\n",
    "\n",
    "            #Aggregate data\n",
    "            bk_data = pd.concat([bk_data, temp_data], axis = 1)\n",
    "        else:\n",
    "            #Aggregate vertically\n",
    "            bk_data = bk_data.append(temp_data, ignore_index = True)\n",
    "    \n",
    "    #If horizontal add match api id to data\n",
    "    if(horizontal == True):\n",
    "        temp_data.loc[:, 'match_api_id'] = matches.loc[:, 'match_api_id']\n",
    "    \n",
    "    #Return bookkeeper data\n",
    "    return bk_data\n",
    "    \n",
    "def get_bookkeeper_probs(matches, bookkeepers, horizontal = False):\n",
    "    ''' Get bookkeeper data and convert to probabilities for vertical aggregation. '''\n",
    "    \n",
    "    #Get bookkeeper data\n",
    "    data = get_bookkeeper_data(matches, bookkeepers, horizontal = False)\n",
    "    \n",
    "    #Convert odds to probabilities\n",
    "    probs = convert_odds_to_prob(data)\n",
    "    \n",
    "    #Return data\n",
    "    return probs\n",
    "\n",
    "def plot_confusion_matrix(y_test, X_test, clf, dim_reduce, path, cmap=plt.cm.Blues, normalize = False):    \n",
    "    ''' Plot confusion matrix for given classifier and data. '''\n",
    "    \n",
    "    #Define label names and get confusion matrix values\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "    cm = confusion_matrix(y_test, clf.predict(dim_reduce.transform(X_test)), labels)\n",
    "    \n",
    "    #Check if matrix should be normalized\n",
    "    if normalize == True:\n",
    "        \n",
    "        #Normalize\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "        \n",
    "    #Configure figure\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\" : False})\n",
    "    fig = plt.figure(1)    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap = plt.cm.Blues)\n",
    "    title= \"Confusion matrix of a {} with {}\".format(best_clf.base_estimator.__class__.__name__, best_dm_reduce.__class__.__name__)   \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #Print classification report\n",
    "    y_pred = clf.predict(dim_reduce.transform(X_test))\n",
    "    print(classification_report(y_test, y_pred)) \n",
    "    \n",
    "def compare_probabilities(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, verbose = False):\n",
    "    ''' Map bookkeeper and model probabilities. '''\n",
    "    \n",
    "    #Create features and labels for given matches\n",
    "    feables = create_feables(matches, fifa_data, bk, get_overall = True, verbose = False)\n",
    "    \n",
    "    #Ensure consistency\n",
    "    match_ids = list(feables['match_api_id'])\n",
    "    matches = matches[matches['match_api_id'].isin(match_ids)]\n",
    "    \n",
    "    #Get bookkeeper probabilities\n",
    "    if verbose == True:\n",
    "        print(\"Obtaining bookkeeper probabilities...\")\n",
    "    bookkeeper_probs = get_bookkeeper_probs(matches, bookkeepers)\n",
    "    bookkeeper_probs.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    inputs = feables.drop('match_api_id', axis = 1)\n",
    "    labels = inputs.loc[:,'label']\n",
    "    features = inputs.drop('label', axis = 1)\n",
    "    \n",
    "    #Get model probabilities\n",
    "    if verbose == True:\n",
    "        print(\"Predicting probabilities based on model...\")\n",
    "    model_probs = pd.DataFrame()\n",
    "    label_table = pd.Series()\n",
    "    temp_probs = pd.DataFrame(clf.predict_proba(dim_reduce.transform(features)), columns = ['win_prob', 'draw_prob', 'defeat_prob'])\n",
    "    for bookkeeper in bookkeepers:\n",
    "        model_probs = model_probs.append(temp_probs, ignore_index = True)\n",
    "        label_table = label_table.append(labels)\n",
    "    model_probs.reset_index(inplace = True, drop = True)\n",
    "    label_table.reset_index(inplace = True, drop = True)\n",
    "    bookkeeper_probs['win_prob'] = model_probs['win_prob']\n",
    "    bookkeeper_probs['draw_prob'] = model_probs['draw_prob']\n",
    "    bookkeeper_probs['defeat_prob'] = model_probs['defeat_prob']\n",
    "    bookkeeper_probs['label'] = label_table \n",
    "    \n",
    "    #Aggregate win probabilities for each match\n",
    "    wins = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Win', 'win_prob', 'label']]\n",
    "    wins.loc[:, 'bet'] = 'Win'\n",
    "    wins = wins.rename(columns = {'Win':'bookkeeper_prob',\n",
    "                                  'win_prob': 'model_prob'})\n",
    "                                  \n",
    "    #Aggregate draw probabilities for each match\n",
    "    draws = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Draw', 'draw_prob', 'label']]\n",
    "    draws.loc[:, 'bet'] = 'Draw'\n",
    "    draws = draws.rename(columns = {'Draw':'bookkeeper_prob',\n",
    "                                  'draw_prob': 'model_prob'})\n",
    "                                  \n",
    "    #Aggregate defeat probabilities for each match\n",
    "    defeats = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Defeat', 'defeat_prob', 'label']]\n",
    "    defeats.loc[:, 'bet'] = 'Defeat'\n",
    "    defeats = defeats.rename(columns = {'Defeat':'bookkeeper_prob',\n",
    "                                  'defeat_prob': 'model_prob'})\n",
    "    \n",
    "    total = pd.concat([wins, draws, defeats])\n",
    "    \n",
    "    #Return total\n",
    "    return total\n",
    "    \n",
    "def find_good_bets(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, percentile, prob_cap, verbose = False):\n",
    "    ''' Find good bets for a given classifier and matches. '''\n",
    "    \n",
    "    #Compare model and classifier probabilities\n",
    "    probs = compare_probabilities(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, verbose = False)\n",
    "    probs.loc[:, 'prob_difference'] = probs.loc[:,\"model_prob\"] - probs.loc[:,\"bookkeeper_prob\"]\n",
    "    \n",
    "    #Sort by createst difference to identify most underestimated bets    \n",
    "    values = probs['prob_difference']\n",
    "    values = values.sort_values(ascending = False)\n",
    "    values.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Selecting attractive bets...\")\n",
    "        \n",
    "    #Identify choices that fulfill requirements such as positive difference, minimum probability and match outcome\n",
    "    relevant_choices = probs[(probs.prob_difference > 0) & (probs.model_prob > prob_cap) & (probs.bet != \"Draw\")]\n",
    "    \n",
    "    #Select given percentile of relevant choices    \n",
    "    top_percent = 1 - percentile\n",
    "    choices = relevant_choices[relevant_choices.prob_difference >= relevant_choices.prob_difference.quantile(top_percent)]\n",
    "    choices.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #Return choices\n",
    "    return choices\n",
    "\n",
    "def get_reward(choice, matches):\n",
    "    ''' Get the reward of a given bet. '''\n",
    "    \n",
    "    #Identify bet\n",
    "    match = matches[matches.match_api_id == choice.match_api_id]\n",
    "    bet_data = match.loc[:,(match.columns.str.contains(choice.bookkeeper))]\n",
    "    cols = bet_data.columns.values\n",
    "    cols[:3] = ['win','draw','defeat']\n",
    "    bet_data.columns = cols\n",
    "    \n",
    "    #Identfiy bet type and get quota\n",
    "    if choice.bet == 'Win':\n",
    "        bet_quota = bet_data.win.values\n",
    "    elif choice.bet == 'Draw':\n",
    "        bet_quota = bet_data.draw.values\n",
    "    elif choice.bet == 'Defeat':\n",
    "        bet_quota = bet_data.defeat.values\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    \n",
    "    #Check label and compute reward\n",
    "    if choice.bet == choice.label:\n",
    "        reward = bet_quota\n",
    "    else:\n",
    "        reward = 0\n",
    "    \n",
    "    #Return reward\n",
    "    return reward\n",
    "      \n",
    "def execute_bets(bet_choices, matches, verbose = False):\n",
    "    ''' Get rewards for all bets. '''    \n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Obtaining reward for chosen bets...\")\n",
    "    total_reward = 0\n",
    "    total_invested = 0\n",
    "    \n",
    "    #Loop through bets\n",
    "    loops = np.arange(0, bet_choices.shape[0])     \n",
    "    for i in loops:\n",
    "        \n",
    "        #Get rewards and accumulate profit\n",
    "        reward = get_reward(bet_choices.iloc[i,:], matches)\n",
    "        total_reward = total_reward + reward\n",
    "        total_invested += 1\n",
    "    \n",
    "    #Compute investment return\n",
    "    investment_return = float(total_reward / total_invested) - 1\n",
    "    \n",
    "    #Return investment return\n",
    "    return investment_return\n",
    "    \n",
    "def explore_data(features, inputs, path):\n",
    "    ''' Explore data by plotting KDE graphs. '''\n",
    "    \n",
    "    #Define figure subplots\n",
    "    fig = plt.figure(1)\n",
    "    fig.subplots_adjust(bottom= -1, left=0.025, top = 2, right=0.975)\n",
    "    \n",
    "    #Loop through features    \n",
    "    i = 1\n",
    "    for col in features.columns:\n",
    "        \n",
    "        #Set subplot and plot format        \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.set_context(\"paper\", font_scale = 0.5, rc={\"lines.linewidth\": 1})\n",
    "        plt.subplot(7,7,0 + i)\n",
    "        j = i - 1\n",
    "        \n",
    "        #Plot KDE for all labels\n",
    "        sns.distplot(inputs[inputs['label'] == 'Win'].iloc[:,j], hist = False, label = 'Win')\n",
    "        sns.distplot(inputs[inputs['label'] == 'Draw'].iloc[:,j], hist = False, label = 'Draw')\n",
    "        sns.distplot(inputs[inputs['label'] == 'Defeat'].iloc[:,j], hist = False, label = 'Defeat')\n",
    "        plt.legend();\n",
    "        i = i + 1\n",
    "    \n",
    "    #Define plot format    \n",
    "    DefaultSize = fig.get_size_inches()\n",
    "    fig.set_size_inches((DefaultSize[0]*1.2, DefaultSize[1]*1.2))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #Compute and print label weights\n",
    "    labels = inputs.loc[:,'label']\n",
    "    class_weights = labels.value_counts() / len(labels)\n",
    "    print(class_weights)\n",
    "    \n",
    "    #Store description of all features\n",
    "    feature_details = features.describe().transpose()\n",
    "\n",
    "    #Return feature details\n",
    "    return feature_details\n",
    "\n",
    "def find_best_classifier(classifiers, dm_reductions, scorer, X_t, y_t, X_c, y_c, X_v, y_v, cv_sets, params, jobs):\n",
    "    ''' Tune all classifier and dimensionality reduction combiantions to find best classifier. '''\n",
    "    \n",
    "    #Initialize result storage\n",
    "    clfs_return = []\n",
    "    dm_reduce_return = []\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    #Loop through dimensionality reductions\n",
    "    for dm in dm_reductions:\n",
    "        \n",
    "        #Loop through classifiers\n",
    "        for clf in clfs:\n",
    "            \n",
    "            #Grid search, calibrate, and test the classifier\n",
    "            clf, dm_reduce, train_score, test_score = train_calibrate_predict(clf = clf, dm_reduction = dm, X_train = X_t, y_train = y_t,\n",
    "                                                      X_calibrate = X_c, y_calibrate = y_c,\n",
    "                                                      X_test = X_v, y_test = y_v, cv_sets = cv_sets,\n",
    "                                                      params = params[clf], scorer = scorer, jobs = jobs, use_grid_search = True)\n",
    "            \n",
    "            #Append the result to storage            \n",
    "            clfs_return.append(clf)\n",
    "            dm_reduce_return.append(dm_reduce)\n",
    "            train_scores.append(train_score)\n",
    "            test_scores.append(test_score)\n",
    "    \n",
    "    #Return storage\n",
    "    return clfs_return, dm_reduce_return, train_scores, test_scores\n",
    "\n",
    "def plot_training_results(clfs, dm_reductions, train_scores, test_scores, path):\n",
    "    ''' Plot results of classifier training. '''\n",
    "    \n",
    "    #Set graph format\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale = 1, rc={\"lines.linewidth\": 1})\n",
    "    ax = plt.subplot(111)\n",
    "    w = 0.5\n",
    "    x = np.arange(len(train_scores))\n",
    "    ax.set_yticks(x + w)\n",
    "    ax.legend((train_scores[0], test_scores[0]), (\"Train Scores\", \"Test Scores\"))\n",
    "    names = []\n",
    "    \n",
    "    #Loop throuugh classifiers\n",
    "    for i in range(0, len(clfs)): \n",
    "        \n",
    "        #Define temporary variables        \n",
    "        clf = clfs[i]\n",
    "        clf_name = clf.base_estimator.__class__.__name__\n",
    "        dm = dm_reductions[i]\n",
    "        dm_name = dm.__class__.__name__\n",
    "        \n",
    "        #Create and store name\n",
    "        name = \"{} with {}\".format(clf_name, dm_name)\n",
    "        names.append(name)\n",
    "        \n",
    "    #Plot all names in horizontal bar plot\n",
    "    ax.set_yticklabels((names))\n",
    "    plt.xlim(0.5, 0.55)\n",
    "    plt.barh(x, test_scores, color = 'b', alpha = 0.6)\n",
    "    plt.title(\"Test Data Accuracy Scores\")\n",
    "    fig = plt.figure(1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def optimize_betting(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, match_data, fifa_data,\n",
    "                     n_samples, sample_size, parameter_1_grid, parameter_2_grid, verbose = False):\n",
    "    ''' Tune parameters of bet selection algorithm. '''\n",
    "    \n",
    "    #Generate data samples\n",
    "    samples = []\n",
    "    for i in range(0, n_samples):\n",
    "        sample = match_data.sample(n = sample_size, random_state = 42)\n",
    "        samples.append(sample)\n",
    "    \n",
    "    results = pd.DataFrame(columns = [\"parameter_1\", \"parameter_2\", \"results\"])\n",
    "    row = 0\n",
    "    \n",
    "    #Iterate over all 1 parameter\n",
    "    for i in parameter_1_grid:\n",
    "        \n",
    "        #Iterate over all 2 parameter\n",
    "        for j in parameter_2_grid:\n",
    "            \n",
    "            #Compute average score over all samples\n",
    "            profits = []\n",
    "            for sample in samples:\n",
    "                choices = find_good_bets(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, sample, fifa_data, i, j)\n",
    "                profit = execute_bets(choices, match_data)\n",
    "                profits.append(profit)\n",
    "            result = np.mean(np.array(profits))\n",
    "            results.loc[row,\"results\"] = result\n",
    "            results.loc[row,\"parameter_1\"] = i\n",
    "            results.loc[row,\"parameter_2\"] = j\n",
    "            row = row + 1\n",
    "            if verbose == True: print(\"Simulated parameter combination: {}\".format(row))\n",
    "               \n",
    "    #Return best setting and result\n",
    "    best_result = results.ix[results['results'].idxmax()] \n",
    "    return best_result\n",
    "\n",
    "def plot_bookkeeper_cf_matrix(matches, bookkeepers, path, verbose = False, normalize = True):\n",
    "    ''' Plot confusion matrix of bookkeeper predictions. '''\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining labels...\")\n",
    "    \n",
    "    #Get match labels\n",
    "    y_test_temp = matches.apply(get_match_label, axis = 1)\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining bookkeeper probabilities...\")\n",
    "    \n",
    "    #Get bookkeeper probabilities\n",
    "    bookkeeper_probs = get_bookkeeper_probs(matches, bookkeepers)\n",
    "    bookkeeper_probs.reset_index(inplace = True, drop = True)\n",
    "    bookkeeper_probs.dropna(inplace = True)\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining bookkeeper labels...\")\n",
    "    \n",
    "    #Get bookkeeper labels\n",
    "    y_pred_temp = pd.DataFrame()\n",
    "    y_pred_temp.loc[:,'bk_label'] = bookkeeper_probs[['Win', 'Draw', 'Defeat']].idxmax(axis = 1)\n",
    "    y_pred_temp.loc[:,'match_api_id'] = bookkeeper_probs.loc[:, 'match_api_id']\n",
    "    \n",
    "    if verbose == True: print(\"Plotting confusion matrix...\")\n",
    "    \n",
    "    #Format data\n",
    "    results = pd.merge(y_pred_temp, y_test_temp, on = 'match_api_id', how = 'left')\n",
    "    y_test = results.loc[:, 'label']\n",
    "    y_pred = results.loc[:, 'bk_label']\n",
    "    \n",
    "    #Generate confusion matrix\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "    cm = confusion_matrix(y_test, y_pred, labels) \n",
    "    \n",
    "    #Check for normalization\n",
    "    if normalize == True:\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "        \n",
    "    #Plot confusion matrix\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\" : False})\n",
    "    fig = plt.figure(1)    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap = plt.cm.Blues)\n",
    "    title = \"Confusion matrix of Bookkeeper predictions!\"   \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #Print classification report and accuracy score of bookkeepers\n",
    "    print(classification_report(y_test, y_pred)) \n",
    "    print(\"Bookkeeper score for test set: {:.4f}.\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>league_id</th>\n",
       "      <th>stage</th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>home_team_api_id</th>\n",
       "      <th>away_team_api_id</th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "      <th>home_player_X1</th>\n",
       "      <th>...</th>\n",
       "      <th>SJA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>GBH</th>\n",
       "      <th>GBD</th>\n",
       "      <th>GBA</th>\n",
       "      <th>BSH</th>\n",
       "      <th>BSD</th>\n",
       "      <th>BSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25979.000000</td>\n",
       "      <td>25979.000000</td>\n",
       "      <td>25979.000000</td>\n",
       "      <td>25979.000000</td>\n",
       "      <td>2.597900e+04</td>\n",
       "      <td>25979.000000</td>\n",
       "      <td>25979.000000</td>\n",
       "      <td>25979.000000</td>\n",
       "      <td>25979.000000</td>\n",
       "      <td>24158.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17097.000000</td>\n",
       "      <td>22568.000000</td>\n",
       "      <td>22568.000000</td>\n",
       "      <td>22568.000000</td>\n",
       "      <td>14162.000000</td>\n",
       "      <td>14162.000000</td>\n",
       "      <td>14162.000000</td>\n",
       "      <td>14161.000000</td>\n",
       "      <td>14161.000000</td>\n",
       "      <td>14161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12990.000000</td>\n",
       "      <td>11738.630317</td>\n",
       "      <td>11738.630317</td>\n",
       "      <td>18.242773</td>\n",
       "      <td>1.195429e+06</td>\n",
       "      <td>9984.371993</td>\n",
       "      <td>9984.475115</td>\n",
       "      <td>1.544594</td>\n",
       "      <td>1.160938</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>...</td>\n",
       "      <td>4.622343</td>\n",
       "      <td>2.668107</td>\n",
       "      <td>3.899048</td>\n",
       "      <td>4.840281</td>\n",
       "      <td>2.498764</td>\n",
       "      <td>3.648189</td>\n",
       "      <td>4.353097</td>\n",
       "      <td>2.497894</td>\n",
       "      <td>3.660742</td>\n",
       "      <td>4.405663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7499.635658</td>\n",
       "      <td>7553.936759</td>\n",
       "      <td>7553.936759</td>\n",
       "      <td>10.407354</td>\n",
       "      <td>4.946279e+05</td>\n",
       "      <td>14087.453758</td>\n",
       "      <td>14087.445135</td>\n",
       "      <td>1.297158</td>\n",
       "      <td>1.142110</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>...</td>\n",
       "      <td>3.632164</td>\n",
       "      <td>1.928753</td>\n",
       "      <td>1.248221</td>\n",
       "      <td>4.318338</td>\n",
       "      <td>1.489299</td>\n",
       "      <td>0.867440</td>\n",
       "      <td>3.010189</td>\n",
       "      <td>1.507793</td>\n",
       "      <td>0.868272</td>\n",
       "      <td>3.189814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.831290e+05</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>1.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6495.500000</td>\n",
       "      <td>4769.000000</td>\n",
       "      <td>4769.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.684365e+05</td>\n",
       "      <td>8475.000000</td>\n",
       "      <td>8475.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.550000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12990.000000</td>\n",
       "      <td>10257.000000</td>\n",
       "      <td>10257.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.147511e+06</td>\n",
       "      <td>8697.000000</td>\n",
       "      <td>8697.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19484.500000</td>\n",
       "      <td>17642.000000</td>\n",
       "      <td>17642.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.709852e+06</td>\n",
       "      <td>9925.000000</td>\n",
       "      <td>9925.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.620000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25979.000000</td>\n",
       "      <td>24558.000000</td>\n",
       "      <td>24558.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.216672e+06</td>\n",
       "      <td>274581.000000</td>\n",
       "      <td>274581.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    country_id     league_id         stage  match_api_id  \\\n",
       "count  25979.000000  25979.000000  25979.000000  25979.000000  2.597900e+04   \n",
       "mean   12990.000000  11738.630317  11738.630317     18.242773  1.195429e+06   \n",
       "std     7499.635658   7553.936759   7553.936759     10.407354  4.946279e+05   \n",
       "min        1.000000      1.000000      1.000000      1.000000  4.831290e+05   \n",
       "25%     6495.500000   4769.000000   4769.000000      9.000000  7.684365e+05   \n",
       "50%    12990.000000  10257.000000  10257.000000     18.000000  1.147511e+06   \n",
       "75%    19484.500000  17642.000000  17642.000000     27.000000  1.709852e+06   \n",
       "max    25979.000000  24558.000000  24558.000000     38.000000  2.216672e+06   \n",
       "\n",
       "       home_team_api_id  away_team_api_id  home_team_goal  away_team_goal  \\\n",
       "count      25979.000000      25979.000000    25979.000000    25979.000000   \n",
       "mean        9984.371993       9984.475115        1.544594        1.160938   \n",
       "std        14087.453758      14087.445135        1.297158        1.142110   \n",
       "min         1601.000000       1601.000000        0.000000        0.000000   \n",
       "25%         8475.000000       8475.000000        1.000000        0.000000   \n",
       "50%         8697.000000       8697.000000        1.000000        1.000000   \n",
       "75%         9925.000000       9925.000000        2.000000        2.000000   \n",
       "max       274581.000000     274581.000000       10.000000        9.000000   \n",
       "\n",
       "       home_player_X1  ...           SJA           VCH           VCD  \\\n",
       "count    24158.000000  ...  17097.000000  22568.000000  22568.000000   \n",
       "mean         0.999586  ...      4.622343      2.668107      3.899048   \n",
       "std          0.022284  ...      3.632164      1.928753      1.248221   \n",
       "min          0.000000  ...      1.100000      1.030000      1.620000   \n",
       "25%          1.000000  ...      2.500000      1.700000      3.300000   \n",
       "50%          1.000000  ...      3.500000      2.150000      3.500000   \n",
       "75%          1.000000  ...      5.250000      2.800000      4.000000   \n",
       "max          2.000000  ...     41.000000     36.000000     26.000000   \n",
       "\n",
       "                VCA           GBH           GBD           GBA           BSH  \\\n",
       "count  22568.000000  14162.000000  14162.000000  14162.000000  14161.000000   \n",
       "mean       4.840281      2.498764      3.648189      4.353097      2.497894   \n",
       "std        4.318338      1.489299      0.867440      3.010189      1.507793   \n",
       "min        1.080000      1.050000      1.450000      1.120000      1.040000   \n",
       "25%        2.550000      1.670000      3.200000      2.500000      1.670000   \n",
       "50%        3.500000      2.100000      3.300000      3.400000      2.100000   \n",
       "75%        5.400000      2.650000      3.750000      5.000000      2.620000   \n",
       "max       67.000000     21.000000     11.000000     34.000000     17.000000   \n",
       "\n",
       "                BSD           BSA  \n",
       "count  14161.000000  14161.000000  \n",
       "mean       3.660742      4.405663  \n",
       "std        0.868272      3.189814  \n",
       "min        1.330000      1.120000  \n",
       "25%        3.250000      2.500000  \n",
       "50%        3.400000      3.400000  \n",
       "75%        3.750000      5.000000  \n",
       "max       13.000000     34.000000  \n",
       "\n",
       "[8 rows x 105 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_id          0\n",
       "league_id           0\n",
       "season              0\n",
       "stage               0\n",
       "date                0\n",
       "match_api_id        0\n",
       "home_team_api_id    0\n",
       "away_team_api_id    0\n",
       "home_team_goal      0\n",
       "away_team_goal      0\n",
       "country             0\n",
       "league              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "with sqlite3.connect('dataset/database.sqlite') as con:\n",
    "    countries = pd.read_sql_query(\"SELECT * from Country\", con)\n",
    "    matches = pd.read_sql_query(\"SELECT * from Match\", con)\n",
    "    leagues = pd.read_sql_query(\"SELECT * from League\", con)\n",
    "    teams = pd.read_sql_query(\"SELECT * from Team\", con)\n",
    "    player = pd.read_sql_query(\"SELECT * from Player\",con)\n",
    "    player_attributes = pd.read_sql_query(\"SELECT * from Player_Attributes\",con)\n",
    "    sequence = pd.read_sql_query(\"SELECT * from sqlite_sequence\",con)\n",
    "    team_attributes = pd.read_sql_query(\"SELECT * from Team_Attributes\",con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Data\n",
    "\n",
    "# FTR = Full Time Result (H=Home, D=Draw, A=Away Win)\n",
    "X_all = data.drop(['result'], axis=1)\n",
    "y_all = data['result']\n",
    "\n",
    "from sklearn.preprocessing import scale\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
